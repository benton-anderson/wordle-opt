{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     word       count\n",
      "25  WHICH  3140226612\n",
      "33  THEIR  2152980325\n",
      "40  THERE  1623700147\n",
      "46  WOULD  1472811049\n",
      "51  OTHER  1383185827\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "word_df=pd.read_csv('5-letter.csv', index_col=0)\n",
    "print(word_df.head())\n",
    "word_list = word_df.word.iloc[0:5000,].to_list()\n",
    "#print(word_list)\n",
    "print(len(word_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5403], dtype=int64),)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(word_df.word==\"SUBSP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wordle:\n",
    "    def __init__(self, word=None, n_guesses=6, n_letters=5, all_words=['PROOF','SHEAR','BUMPY']):\n",
    "        if word == None:\n",
    "            self.word = random.sample(set(all_words), 1)[0]\n",
    "        else:\n",
    "            self.word = word.upper()\n",
    "        self.n_guesses = n_guesses\n",
    "        self.n_letters = n_letters\n",
    "        self.guess_counter = n_guesses\n",
    "        self.greens = [None] * self.n_letters \n",
    "        self.current_yellows = [None] * self.n_letters\n",
    "        self.yellows = {i: [] for i in range(self.n_letters)}\n",
    "        self.guessed_words = []\n",
    "        self.all_words = all_words\n",
    "        self.absent_letters = []\n",
    "        self.present_letters = []\n",
    "        self.correct_positions = [None] * self.n_letters # greens would be differnt per guess, remember correct positions\n",
    "        self.state = None\n",
    "        self.qstate = [0] * self.n_letters\n",
    "        \n",
    "    def try_word (self, guess):\n",
    "        # need to add a check for not doing anything if the word is already guessed correctly\n",
    "        guess = guess.upper()\n",
    "        self.state = None\n",
    "        self.current_yellows = [None]* self.n_letters # yellows have to reset each time\n",
    "        self.greens = [None] * self.n_letters\n",
    "        print('guessed: ', guess)\n",
    "        if not len(guess) == self.n_letters:\n",
    "            raise ValueError('wrong word length')\n",
    "        if guess not in self.all_words:\n",
    "            raise ValueError('invalid word')\n",
    "        if guess in self.guessed_words:\n",
    "            raise ValueError('word already guessed')\n",
    "        self.guessed_words.append(guess)\n",
    "        # c_g = character_guess,  c_w = character_word\n",
    "        for i, (c_g, c_w) in enumerate(zip(guess, self.word)):\n",
    "            if c_g == c_w:\n",
    "                self.greens[i] = c_g\n",
    "                self.correct_positions[i] = c_g\n",
    "                self.qstate[i] = 1\n",
    "            # Check for number of non-None in greens list \n",
    "            if sum(bool(char) for char in self.greens) == self.n_letters:\n",
    "                self.state = True\n",
    "                return 'victory! word is: ' + self.word\n",
    "                \n",
    "            if c_g in self.word and c_g != c_w:\n",
    "                self.yellows[i].append(c_g)\n",
    "                self.current_yellows[i] = c_g\n",
    "            if c_g in self.word: # track the letters that are there for the AI later\n",
    "                self.present_letters.append(c_g)\n",
    "            if c_g not in self.word: # track letters that are not there for the AI\n",
    "                self.absent_letters.append(c_g)\n",
    "        self.guess_counter -= 1\n",
    "        grn_sum = sum([x!=None for x in self.greens])\n",
    "        yel_sum = sum([x!=None for x in self.current_yellows])\n",
    "        \n",
    "        if self.guess_counter == 0:\n",
    "            self.state=True\n",
    "            print(\"YOU LOSE-TOO MANY GUESSES\")\n",
    "            return grn_sum, yel_sum # return number of greens and number of yellows\n",
    "        print('Greens:' + str(self.greens) + \n",
    "              '\\nYellows: ' + str(self.yellows) + \n",
    "              '\\nGuesses left: ' + str(self.guess_counter))\n",
    "\n",
    "        return grn_sum, yel_sum # return number of greens and number of yellows\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Wordle(all_words = word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# player agent class\n",
    "\n",
    "## this is where we can have different 'types' of word guesses to be optimized\n",
    "class Player:\n",
    "    def __init__(self, all_words):\n",
    "        self.guesses=0\n",
    "        self.guessed_words = []\n",
    "        self.all_words = all_words\n",
    "        \n",
    "    def get_random_guess(self):\n",
    "        '''\n",
    "        make a guess randomly from the word list\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        current_guess = random.sample(set(self.all_words), 1)[0]\n",
    "        self.guessed_words.append(current_guess)\n",
    "        return current_guess\n",
    "    def get_common_guess(self):\n",
    "        i=0\n",
    "        while( self.all_words[i] in self.guessed_words):\n",
    "            i+=1\n",
    "        return self.all_words[i]\n",
    "    #def guess_by_green(self):\n",
    "        \n",
    "        \n",
    "    #def guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## need an environment class that lets the player interact with wordl\n",
    "class Environment:\n",
    "    REWARD_YELLOW = 1\n",
    "    REWARD_GREEN = 10\n",
    "    REWARD_WIN = 100\n",
    "    REWARD_LOSE = -500\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.game_over = False\n",
    "        self.score = 0\n",
    "        self.player = Player(all_words = word_list)\n",
    "        self.wordle = Wordle(all_words=word_list)\n",
    "        print(self.wordle.word)\n",
    "        self.guesses = 0\n",
    "        self.action_space = [0,1]\n",
    "        \n",
    "    def step(self, action):\n",
    "        self.guesses += 1\n",
    "        \n",
    "        if action==0:\n",
    "            current_guess = self.player.get_random_guess()\n",
    "        elif action == 1:\n",
    "            current_guess = self.player.get_common_guess()\n",
    "        \n",
    "        n_greens, n_yellows = self.wordle.try_word(current_guess)\n",
    "        reward = 0\n",
    "        \n",
    "        if n_greens>0:\n",
    "            reward += self.REWARD_GREEN * n_greens\n",
    "            self.score +=self.REWARD_GREEN\n",
    "        if n_yellows>0:\n",
    "            reward += self.REWARD_YELLOW * n_yellows\n",
    "            self.score +=self.REWARD_YELLOW * n_yellows\n",
    "            \n",
    "        if self.wordle.state == 'WIN':\n",
    "            reward += self.REWARD_WIN\n",
    "            self.score +=self.REWARD_WIN\n",
    "            return state, reward, self.wordle.state\n",
    "        \n",
    "        result = self.wordle.qstate\n",
    "        \n",
    "        return result, reward, self.wordle.state\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOMES\n"
     ]
    }
   ],
   "source": [
    "e = Environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guessed:  NORSE\n",
      "Greens:[None, 'O', None, None, None]\n",
      "Yellows: {0: [], 1: [], 2: [], 3: ['S'], 4: ['E']}\n",
      "Guesses left: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0, 1, 0, 0, 0], 12, None)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import itertools\n",
    "import matplotlib\n",
    "import matplotlib.style\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "  \n",
    "  \n",
    "from collections import defaultdict\n",
    "\n",
    "import plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym_gridworlds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Gridworld-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gym.spaces.discrete.Discrete"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.contrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-345662a2ae65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicies\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMlpPolicy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvec_env\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDummyVecEnv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPPO2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\sklearn\\lib\\site-packages\\stable_baselines\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mACER\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macktr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mACKTR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepq\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDQN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mher\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHER\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPPO2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\sklearn\\lib\\site-packages\\stable_baselines\\deepq\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicies\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMlpPolicy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCnnPolicy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLnMlpPolicy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLnCnnPolicy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_graph\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbuild_act\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_train\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdqn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDQN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mReplayBuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPrioritizedReplayBuffer\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\sklearn\\lib\\site-packages\\stable_baselines\\deepq\\policies.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf_layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspaces\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDiscrete\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.contrib'"
     ]
    }
   ],
   "source": [
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines import PPO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createEpsilonGreedyPolicy(Q, epsilon, num_actions):\n",
    "\t\"\"\"\n",
    "\tCreates an epsilon-greedy policy based\n",
    "\ton a given Q-function and epsilon.\n",
    "\t\n",
    "\tReturns a function that takes the state\n",
    "\tas an input and returns the probabilities\n",
    "\tfor each action in the form of a numpy array\n",
    "\tof length of the action space(set of possible actions).\n",
    "\t\"\"\"\n",
    "\tdef policyFunction(state):\n",
    "\n",
    "\t\tAction_probabilities = np.ones(num_actions, dtype = float) * epsilon / num_actions\n",
    "\t\tbest_action = np.argmax(Q[state])\n",
    "\t\tAction_probabilities[best_action] += (1.0 - epsilon)\n",
    "\t\treturn Action_probabilities\n",
    "\n",
    "\treturn policyFunction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = defaultdict(lambda: np.zeros(env.action_space.n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-71-9921850256af>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-71-9921850256af>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Q[]\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Q[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GABON\n"
     ]
    }
   ],
   "source": [
    "e = Environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plottingepi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qLearning(env, num_episodes, discount_factor = 1.0, alpha = 0.6, epsilon = 0.1):\n",
    "    \"\"\"\n",
    "    Q-Learning algorithm: Off-policy TD control.\n",
    "    Finds the optimal greedy policy while improving\n",
    "    following an epsilon-greedy policy\"\"\"\n",
    "    \n",
    "    # Action value function\n",
    "    # A nested dictionary that maps\n",
    "    # state -> (action -> action-value).\n",
    "    Q = defaultdict(lambda: np.zeros(len(env.action_space)))\n",
    "\n",
    "    # Keeps track of useful statistics\n",
    "    stats = plottingepi.EpisodeStats(\n",
    "        episode_lengths = np.zeros(num_episodes),\n",
    "        episode_rewards = np.zeros(num_episodes))\t\n",
    "    \n",
    "    # Create an epsilon greedy policy function\n",
    "    # appropriately for environment action space\n",
    "    policy = createEpsilonGreedyPolicy(Q, epsilon, len(env.action_space) )\n",
    "    \n",
    "    # For every episode\n",
    "    for ith_episode in range(num_episodes):\n",
    "\n",
    "        # Reset the environment and pick the first action\n",
    "        state = env.reset()\n",
    "        \n",
    "        for t in itertools.count():\n",
    "            print(\"this is q\", Q)\n",
    "            # get probabilities of all actions from current state\n",
    "            action_probabilities = policy(state)\n",
    "            print(action_probabilities)\n",
    "            # choose action according to\n",
    "            # the probability distribution\n",
    "            action = np.random.choice(np.arange(\n",
    "                    len(action_probabilities)),\n",
    "                    p = action_probabilities)\n",
    "            print('this is the action', action)\n",
    "            # take action and get reward, transit to next state\n",
    "            next_state, reward, done = env.step(action)\n",
    "            print(sum(next_state))\n",
    "            next_state = sum(next_state)\n",
    "            # Update statistics\n",
    "            stats.episode_rewards[ith_episode] += reward\n",
    "            stats.episode_lengths[ith_episode] = t\n",
    "\n",
    "            # TD Update\n",
    "            best_next_action = np.argmax(Q[next_state])\t\n",
    "            td_target = reward + discount_factor * Q[next_state][best_next_action]\n",
    "            td_delta = td_target - Q[state][action]\n",
    "            Q[state][action] += alpha * td_delta\n",
    "\n",
    "            # done is True if episode terminated\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "    return Q, stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPRAY\n",
      "VOTED\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  NOBLE\n",
      "Greens:[None, 'O', None, None, None]\n",
      "Yellows: {0: [], 1: [], 2: [], 3: [], 4: ['E']}\n",
      "Guesses left: 5\n",
      "1\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([6.6, 0. ]), 1: array([0., 0.])})\n",
      "[0.95 0.05]\n",
      "this is the action 1\n",
      "guessed:  WHICH\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: [], 1: [], 2: [], 3: [], 4: ['E']}\n",
      "Guesses left: 4\n",
      "1\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([6.6, 0. ]), 1: array([0., 0.])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  GLARE\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: [], 1: [], 2: [], 3: [], 4: ['E', 'E']}\n",
      "Guesses left: 3\n",
      "1\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([6.6, 0. ]), 1: array([0.6, 0. ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  JANIE\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: [], 1: [], 2: [], 3: [], 4: ['E', 'E', 'E']}\n",
      "Guesses left: 2\n",
      "1\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([6.6, 0. ]), 1: array([1.2, 0. ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  ARMED\n",
      "Greens:[None, None, None, 'E', 'D']\n",
      "Yellows: {0: [], 1: [], 2: [], 3: [], 4: ['E', 'E', 'E']}\n",
      "Guesses left: 1\n",
      "3\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([6.6, 0. ]), 1: array([12.48,  0.  ]), 3: array([0., 0.])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  JOYCE\n",
      "YOU LOSE-TOO MANY GUESSES\n",
      "3\n",
      "FITLY\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([6.6, 0. ]), 1: array([12.48,  0.  ]), 3: array([6.6, 0. ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  MIXES\n",
      "Greens:[None, 'I', None, None, None]\n",
      "Yellows: {0: [], 1: [], 2: [], 3: [], 4: []}\n",
      "Guesses left: 5\n",
      "1\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([16.128,  0.   ]), 1: array([12.48,  0.  ]), 3: array([6.6, 0. ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  ETHEL\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: [], 1: ['T'], 2: [], 3: [], 4: ['L']}\n",
      "Guesses left: 4\n",
      "1\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([16.128,  0.   ]), 1: array([13.68,  0.  ]), 3: array([6.6, 0. ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  BOOMS\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: [], 1: ['T'], 2: [], 3: [], 4: ['L']}\n",
      "Guesses left: 3\n",
      "1\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([16.128,  0.   ]), 1: array([13.68,  0.  ]), 3: array([6.6, 0. ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  INTRA\n",
      "Greens:[None, None, 'T', None, None]\n",
      "Yellows: {0: ['I'], 1: ['T'], 2: [], 3: [], 4: ['L']}\n",
      "Guesses left: 2\n",
      "2\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([16.128,  0.   ]), 1: array([12.072,  0.   ]), 3: array([6.6, 0. ]), 2: array([0., 0.])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  POSES\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: ['I'], 1: ['T'], 2: [], 3: [], 4: ['L']}\n",
      "Guesses left: 1\n",
      "2\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([16.128,  0.   ]), 1: array([12.072,  0.   ]), 3: array([6.6, 0. ]), 2: array([0., 0.])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  ADOBE\n",
      "YOU LOSE-TOO MANY GUESSES\n",
      "2\n",
      "SUPER\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([16.128,  0.   ]), 1: array([12.072,  0.   ]), 3: array([6.6, 0. ]), 2: array([0., 0.])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  FAGAN\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: [], 1: [], 2: [], 3: [], 4: []}\n",
      "Guesses left: 5\n",
      "0\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([6.4512, 0.    ]), 1: array([12.072,  0.   ]), 3: array([6.6, 0. ]), 2: array([0., 0.]), 0: array([0., 0.])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  GAUZE\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: [], 1: [], 2: ['U'], 3: [], 4: ['E']}\n",
      "Guesses left: 4\n",
      "0\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([6.4512, 0.    ]), 1: array([12.072,  0.   ]), 3: array([6.6, 0. ]), 2: array([0., 0.]), 0: array([1.2, 0. ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  AUGER\n",
      "Greens:[None, 'U', None, 'E', 'R']\n",
      "Yellows: {0: [], 1: [], 2: ['U'], 3: [], 4: ['E']}\n",
      "Guesses left: 3\n",
      "3\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([6.4512, 0.    ]), 1: array([12.072,  0.   ]), 3: array([6.6, 0. ]), 2: array([0., 0.]), 0: array([22.44,  0.  ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  DRAWN\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: [], 1: ['R'], 2: ['U'], 3: [], 4: ['E']}\n",
      "Guesses left: 2\n",
      "3\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([6.4512, 0.    ]), 1: array([12.072,  0.   ]), 3: array([7.2, 0. ]), 2: array([0., 0.]), 0: array([22.44,  0.  ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  DIGIT\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: [], 1: ['R'], 2: ['U'], 3: [], 4: ['E']}\n",
      "Guesses left: 1\n",
      "3\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([6.4512, 0.    ]), 1: array([12.072,  0.   ]), 3: array([7.2, 0. ]), 2: array([0., 0.]), 0: array([22.44,  0.  ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  JOKER\n",
      "YOU LOSE-TOO MANY GUESSES\n",
      "3\n",
      "DOCKS\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([6.4512, 0.    ]), 1: array([12.072,  0.   ]), 3: array([19.2,  0. ]), 2: array([0., 0.]), 0: array([22.44,  0.  ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  SPOIL\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: ['S'], 1: [], 2: ['O'], 3: [], 4: []}\n",
      "Guesses left: 5\n",
      "0\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([17.24448,  0.     ]), 1: array([12.072,  0.   ]), 3: array([19.2,  0. ]), 2: array([0., 0.]), 0: array([22.44,  0.  ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  UNCLE\n",
      "Greens:[None, None, 'C', None, None]\n",
      "Yellows: {0: ['S'], 1: [], 2: ['O'], 3: [], 4: []}\n",
      "Guesses left: 4\n",
      "1\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([17.24448,  0.     ]), 1: array([12.072,  0.   ]), 3: array([19.2,  0. ]), 2: array([0., 0.]), 0: array([22.2192,  0.    ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  MATED\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: ['S'], 1: [], 2: ['O'], 3: [], 4: ['D']}\n",
      "Guesses left: 3\n",
      "1\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([17.24448,  0.     ]), 1: array([12.672,  0.   ]), 3: array([19.2,  0. ]), 2: array([0., 0.]), 0: array([22.2192,  0.    ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  ALLOY\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: ['S'], 1: [], 2: ['O'], 3: ['O'], 4: ['D']}\n",
      "Guesses left: 2\n",
      "1\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([17.24448,  0.     ]), 1: array([13.272,  0.   ]), 3: array([19.2,  0. ]), 2: array([0., 0.]), 0: array([22.2192,  0.    ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  USING\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: ['S'], 1: ['S'], 2: ['O'], 3: ['O'], 4: ['D']}\n",
      "Guesses left: 1\n",
      "1\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([17.24448,  0.     ]), 1: array([13.872,  0.   ]), 3: array([19.2,  0. ]), 2: array([0., 0.]), 0: array([22.2192,  0.    ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  FUELS\n",
      "YOU LOSE-TOO MANY GUESSES\n",
      "2\n",
      "WILES\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([17.24448,  0.     ]), 1: array([11.5488,  0.    ]), 3: array([19.2,  0. ]), 2: array([0., 0.]), 0: array([22.2192,  0.    ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  CHAFE\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: [], 1: [], 2: [], 3: [], 4: ['E']}\n",
      "Guesses left: 5\n",
      "0\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([20.829312,  0.      ]), 1: array([11.5488,  0.    ]), 3: array([19.2,  0. ]), 2: array([0., 0.]), 0: array([22.2192,  0.    ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  RIGGS\n",
      "Greens:[None, 'I', None, None, 'S']\n",
      "Yellows: {0: [], 1: [], 2: [], 3: [], 4: ['E']}\n",
      "Guesses left: 4\n",
      "2\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([20.829312,  0.      ]), 1: array([11.5488,  0.    ]), 3: array([19.2,  0. ]), 2: array([0., 0.]), 0: array([20.88768,  0.     ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  MANDY\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: [], 1: [], 2: [], 3: [], 4: ['E']}\n",
      "Guesses left: 3\n",
      "2\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([20.829312,  0.      ]), 1: array([11.5488,  0.    ]), 3: array([19.2,  0. ]), 2: array([0., 0.]), 0: array([20.88768,  0.     ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  DROIT\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: [], 1: [], 2: [], 3: ['I'], 4: ['E']}\n",
      "Guesses left: 2\n",
      "2\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([20.829312,  0.      ]), 1: array([11.5488,  0.    ]), 3: array([19.2,  0. ]), 2: array([0.6, 0. ]), 0: array([20.88768,  0.     ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  SAHEL\n",
      "Greens:[None, None, None, 'E', None]\n",
      "Yellows: {0: ['S'], 1: [], 2: [], 3: ['I'], 4: ['E', 'L']}\n",
      "Guesses left: 1\n",
      "3\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([20.829312,  0.      ]), 1: array([11.5488,  0.    ]), 3: array([19.2,  0. ]), 2: array([18.96,  0.  ]), 0: array([20.88768,  0.     ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  FUZZY\n",
      "YOU LOSE-TOO MANY GUESSES\n",
      "3\n",
      "BERKS\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([20.829312,  0.      ]), 1: array([11.5488,  0.    ]), 3: array([19.2,  0. ]), 2: array([18.96,  0.  ]), 0: array([20.88768,  0.     ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  WAREN\n",
      "Greens:[None, None, 'R', None, None]\n",
      "Yellows: {0: [], 1: [], 2: [], 3: ['E'], 4: []}\n",
      "Guesses left: 5\n",
      "1\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([21.8610048,  0.       ]), 1: array([11.5488,  0.    ]), 3: array([19.2,  0. ]), 2: array([18.96,  0.  ]), 0: array([20.88768,  0.     ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  VICKY\n",
      "Greens:[None, None, None, 'K', None]\n",
      "Yellows: {0: [], 1: [], 2: [], 3: ['E'], 4: []}\n",
      "Guesses left: 4\n",
      "2\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([21.8610048,  0.       ]), 1: array([21.99552,  0.     ]), 3: array([19.2,  0. ]), 2: array([18.96,  0.  ]), 0: array([20.88768,  0.     ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  MANNY\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: [], 1: [], 2: [], 3: ['E'], 4: []}\n",
      "Guesses left: 3\n",
      "2\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([21.8610048,  0.       ]), 1: array([21.99552,  0.     ]), 3: array([19.2,  0. ]), 2: array([18.96,  0.  ]), 0: array([20.88768,  0.     ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  MCKEE\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: [], 1: [], 2: ['K'], 3: ['E', 'E'], 4: ['E']}\n",
      "Guesses left: 2\n",
      "2\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([21.8610048,  0.       ]), 1: array([21.99552,  0.     ]), 3: array([19.2,  0. ]), 2: array([20.76,  0.  ]), 0: array([20.88768,  0.     ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  OBEYS\n",
      "Greens:[None, None, None, None, 'S']\n",
      "Yellows: {0: [], 1: ['B'], 2: ['K', 'E'], 3: ['E', 'E'], 4: ['E']}\n",
      "Guesses left: 1\n",
      "3\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([21.8610048,  0.       ]), 1: array([21.99552,  0.     ]), 3: array([19.2,  0. ]), 2: array([27.024,  0.   ]), 0: array([20.88768,  0.     ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  OPTED\n",
      "YOU LOSE-TOO MANY GUESSES\n",
      "3\n",
      "WOKEN\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([21.8610048,  0.       ]), 1: array([21.99552,  0.     ]), 3: array([19.8,  0. ]), 2: array([27.024,  0.   ]), 0: array([20.88768,  0.     ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  ROUEN\n",
      "Greens:[None, 'O', None, 'E', 'N']\n",
      "Yellows: {0: [], 1: [], 2: [], 3: [], 4: []}\n",
      "Guesses left: 5\n",
      "3\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([38.62440192,  0.        ]), 1: array([21.99552,  0.     ]), 3: array([19.8,  0. ]), 2: array([27.024,  0.   ]), 0: array([20.88768,  0.     ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  NATUR\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: ['N'], 1: [], 2: [], 3: [], 4: []}\n",
      "Guesses left: 4\n",
      "3\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([38.62440192,  0.        ]), 1: array([21.99552,  0.     ]), 3: array([20.4,  0. ]), 2: array([27.024,  0.   ]), 0: array([20.88768,  0.     ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  NEWLY\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: ['N', 'N'], 1: ['E'], 2: ['W'], 3: [], 4: []}\n",
      "Guesses left: 3\n",
      "3\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([38.62440192,  0.        ]), 1: array([21.99552,  0.     ]), 3: array([22.2,  0. ]), 2: array([27.024,  0.   ]), 0: array([20.88768,  0.     ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  WALLS\n",
      "Greens:['W', None, None, None, None]\n",
      "Yellows: {0: ['N', 'N'], 1: ['E'], 2: ['W'], 3: [], 4: []}\n",
      "Guesses left: 2\n",
      "4\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([38.62440192,  0.        ]), 1: array([21.99552,  0.     ]), 3: array([14.88,  0.  ]), 2: array([27.024,  0.   ]), 0: array([20.88768,  0.     ]), 4: array([0., 0.])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  DISKS\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: ['N', 'N'], 1: ['E'], 2: ['W'], 3: ['K'], 4: []}\n",
      "Guesses left: 1\n",
      "4\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([38.62440192,  0.        ]), 1: array([21.99552,  0.     ]), 3: array([14.88,  0.  ]), 2: array([27.024,  0.   ]), 0: array([20.88768,  0.     ]), 4: array([0.6, 0. ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  LOBBY\n",
      "YOU LOSE-TOO MANY GUESSES\n",
      "4\n",
      "STIFF\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([38.62440192,  0.        ]), 1: array([21.99552,  0.     ]), 3: array([14.88,  0.  ]), 2: array([27.024,  0.   ]), 0: array([20.88768,  0.     ]), 4: array([6.6, 0. ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  RANKS\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: [], 1: [], 2: [], 3: [], 4: ['S']}\n",
      "Guesses left: 5\n",
      "0\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([28.58236877,  0.        ]), 1: array([21.99552,  0.     ]), 3: array([14.88,  0.  ]), 2: array([27.024,  0.   ]), 0: array([20.88768,  0.     ]), 4: array([6.6, 0. ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  RAZED\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: [], 1: [], 2: [], 3: [], 4: ['S']}\n",
      "Guesses left: 4\n",
      "0\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([28.58236877,  0.        ]), 1: array([21.99552,  0.     ]), 3: array([14.88,  0.  ]), 2: array([27.024,  0.   ]), 0: array([20.88768,  0.     ]), 4: array([6.6, 0. ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  TOMMY\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: ['T'], 1: [], 2: [], 3: [], 4: ['S']}\n",
      "Guesses left: 3\n",
      "0\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([28.58236877,  0.        ]), 1: array([21.99552,  0.     ]), 3: array([14.88,  0.  ]), 2: array([27.024,  0.   ]), 0: array([21.48768,  0.     ]), 4: array([6.6, 0. ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  ABHOR\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: ['T'], 1: [], 2: [], 3: [], 4: ['S']}\n",
      "Guesses left: 2\n",
      "0\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([28.58236877,  0.        ]), 1: array([21.99552,  0.     ]), 3: array([14.88,  0.  ]), 2: array([27.024,  0.   ]), 0: array([21.48768,  0.     ]), 4: array([6.6, 0. ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  BESET\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: ['T'], 1: [], 2: ['S'], 3: [], 4: ['S', 'T']}\n",
      "Guesses left: 1\n",
      "0\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([28.58236877,  0.        ]), 1: array([21.99552,  0.     ]), 3: array([14.88,  0.  ]), 2: array([27.024,  0.   ]), 0: array([22.68768,  0.     ]), 4: array([6.6, 0. ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  SUMMA\n",
      "YOU LOSE-TOO MANY GUESSES\n",
      "1\n",
      "CHILD\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([28.58236877,  0.        ]), 1: array([21.99552,  0.     ]), 3: array([14.88,  0.  ]), 2: array([27.024,  0.   ]), 0: array([28.272384,  0.      ]), 4: array([6.6, 0. ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  DONNA\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: ['D'], 1: [], 2: [], 3: [], 4: []}\n",
      "Guesses left: 5\n",
      "0\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([28.99637791,  0.        ]), 1: array([21.99552,  0.     ]), 3: array([14.88,  0.  ]), 2: array([27.024,  0.   ]), 0: array([28.272384,  0.      ]), 4: array([6.6, 0. ])})\n",
      "[0.95 0.05]\n",
      "this is the action 1\n",
      "guessed:  WHICH\n",
      "Greens:[None, 'H', 'I', None, None]\n",
      "Yellows: {0: ['D'], 1: [], 2: [], 3: ['C'], 4: ['H']}\n",
      "Guesses left: 4\n",
      "2\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([28.99637791,  0.        ]), 1: array([21.99552,  0.     ]), 3: array([14.88,  0.  ]), 2: array([27.024,  0.   ]), 0: array([28.272384, 29.4144  ]), 4: array([6.6, 0. ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  RIOTS\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: ['D'], 1: ['I'], 2: [], 3: ['C'], 4: ['H']}\n",
      "Guesses left: 3\n",
      "2\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([28.99637791,  0.        ]), 1: array([21.99552,  0.     ]), 3: array([14.88,  0.  ]), 2: array([27.624,  0.   ]), 0: array([28.272384, 29.4144  ]), 4: array([6.6, 0. ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  QUINN\n",
      "Greens:[None, None, 'I', None, None]\n",
      "Yellows: {0: ['D'], 1: ['I'], 2: [], 3: ['C'], 4: ['H']}\n",
      "Guesses left: 2\n",
      "2\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([28.99637791,  0.        ]), 1: array([21.99552,  0.     ]), 3: array([14.88,  0.  ]), 2: array([33.624,  0.   ]), 0: array([28.272384, 29.4144  ]), 4: array([6.6, 0. ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  KEEPS\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: ['D'], 1: ['I'], 2: [], 3: ['C'], 4: ['H']}\n",
      "Guesses left: 1\n",
      "2\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([28.99637791,  0.        ]), 1: array([21.99552,  0.     ]), 3: array([14.88,  0.  ]), 2: array([33.624,  0.   ]), 0: array([28.272384, 29.4144  ]), 4: array([6.6, 0. ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  MUMMY\n",
      "YOU LOSE-TOO MANY GUESSES\n",
      "2\n",
      "VIDYA\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([28.99637791,  0.        ]), 1: array([21.99552,  0.     ]), 3: array([14.88,  0.  ]), 2: array([33.624,  0.   ]), 0: array([28.272384, 29.4144  ]), 4: array([6.6, 0. ])})\n",
      "[0.95 0.05]\n",
      "this is the action 0\n",
      "guessed:  MUJER\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: [], 1: [], 2: [], 3: [], 4: []}\n",
      "Guesses left: 5\n",
      "0\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([29.24719116,  0.        ]), 1: array([21.99552,  0.     ]), 3: array([14.88,  0.  ]), 2: array([33.624,  0.   ]), 0: array([28.272384, 29.4144  ]), 4: array([6.6, 0. ])})\n",
      "[0.05 0.95]\n",
      "this is the action 1\n",
      "guessed:  WHICH\n",
      "Greens:[None, None, None, None, None]\n",
      "Yellows: {0: [], 1: [], 2: ['I'], 3: [], 4: []}\n",
      "Guesses left: 4\n",
      "0\n",
      "this is q defaultdict(<function qLearning.<locals>.<lambda> at 0x000001C1E4CADB88>, {None: array([29.24719116,  0.        ]), 1: array([21.99552,  0.     ]), 3: array([14.88,  0.  ]), 2: array([33.624,  0.   ]), 0: array([28.272384, 30.0144  ]), 4: array([6.6, 0. ])})\n",
      "[0.05 0.95]\n",
      "this is the action 1\n",
      "guessed:  WHICH\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "word already guessed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-91f18083ac18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mq1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqLearning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEnvironment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-114-e988d568273e>\u001b[0m in \u001b[0;36mqLearning\u001b[1;34m(env, num_episodes, discount_factor, alpha, epsilon)\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'this is the action'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;31m# take action and get reward, transit to next state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mnext_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-109-cc9b8739ed9c>\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mcurrent_guess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_common_guess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mn_greens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_yellows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwordle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtry_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_guess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-105-1b63f36c8655>\u001b[0m in \u001b[0;36mtry_word\u001b[1;34m(self, guess)\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'invalid word'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mguess\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mguessed_words\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'word already guessed'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mguessed_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mguess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# c_g = character_guess,  c_w = character_word\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: word already guessed"
     ]
    }
   ],
   "source": [
    "q1, s1 = qLearning(Environment(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn",
   "language": "python",
   "name": "sklearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
