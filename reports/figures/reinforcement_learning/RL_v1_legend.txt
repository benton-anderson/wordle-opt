Figure 3: Reinforcement learning optimizes rules for humans playing wordle. A. Scheme showing the concept of reinforcement learning for this task of Wordle. B. Distribution of game rewards at the end after 10,000 trials. Given the large size of the reward for winning at 50, the distribution is bimodal. C. Comparison of ‘best’ versus ‘last’ game state representations for three repeated learning experiments with each setting. ‘Best’ defines the state as the highest total counts of green and yellows and ‘last’ defines the state as the counts of green and yellow in the last guess. D. Distribution of game lengths over 10,000 trials of the game using ‘last’ as the game state. Most games lasted for all six trials. E, F. Optimal policy of overview from an average of the policy learned from 10,000 trials repeated three times using epsilon of 0.5 (E, more exploration) versus 0.02 (F, more exploitation). The row labels give the state of as defined by (# of green letters, # of yellow letters). Each row is normalized so that the highest value is set to 1 and the lowest value is set to zero.  
